{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/guanyu1127/Programming-Language/blob/main/HW4.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# -*- coding: utf-8 -*-\n",
        "\"\"\"\n",
        "# PTT é›»å½±ç‰ˆè¼¿æƒ…åˆ†ææ©Ÿå™¨äºº (v6 - æœ€çµ‚æˆåŠŸç‰ˆ)\n",
        "\n",
        "é€™å€‹ Colab ç­†è¨˜æœ¬æ•´åˆäº†ä¸€å€‹å®Œæ•´çš„è‡ªå‹•åŒ–æµç¨‹ï¼ŒåŒ…å«ï¼š\n",
        "1.  **çˆ¬å– PTT é›»å½±ç‰ˆ**ï¼šæŠ“å–æŒ‡å®šé æ•¸çš„æ–‡ç« æ¨™é¡Œã€‚\n",
        "2.  **å¯«å…¥ Google Sheet**ï¼šå°‡çˆ¬èŸ²çµæœå„²å­˜åˆ° Google Sheetã€‚\n",
        "3.  **è®€å–èˆ‡åˆ†æ**ï¼š\n",
        "    * **TF-IDF**ï¼šè‡ªå‹•æ‰¾å‡ºç†±é–€é—œéµå­—ã€‚\n",
        "    * **è‡ªè¨‚é—œéµå­—**ï¼šçµ±è¨ˆæ‚¨æ‰‹å‹•è¼¸å…¥çš„é—œéµå­—å‡ºç¾æ¬¡æ•¸ã€‚\n",
        "4.  **å›å¯«çµ±è¨ˆçµæœ**ï¼šå°‡å…©ç¨®åˆ†æçµæœåˆ†åˆ¥å¯«å› Google Sheet çš„ä¸åŒå·¥ä½œè¡¨ã€‚\n",
        "5.  **AI ç”Ÿæˆæ‘˜è¦**ï¼šä½¿ç”¨ç¶“è¨ºæ–·ç¢ºèªå¯ç”¨çš„ Gemini API æ¨¡å‹ (gemini-pro-latest) ç”Ÿæˆæ´å¯Ÿæ‘˜è¦èˆ‡çµè«–ã€‚\n",
        "6.  **Gradio äº’å‹•ä»‹é¢**ï¼šæä¾›ä¸€å€‹ç°¡å–®çš„ Web UI ä¾†ä¸€éµåŸ·è¡Œä»¥ä¸Šæ‰€æœ‰æµç¨‹ã€‚\n",
        "\n",
        "è«‹ä¾ç…§ä»¥ä¸‹æ­¥é©ŸåŸ·è¡Œã€‚\n",
        "\"\"\"\n",
        "\n",
        "# @title 1. å®‰è£æ‰€æœ‰å¿…è¦çš„å¥—ä»¶\n",
        "# @markdown ---\n",
        "# @markdown é¦–å…ˆï¼ŒåŸ·è¡Œæ­¤å„²å­˜æ ¼ä¾†å®‰è£æ­¤å°ˆæ¡ˆæ‰€éœ€çš„ Python å¥—ä»¶ã€‚\n",
        "!pip install requests beautifulsoup4 gspread google-auth-oauthlib google-auth-httplib2 pandas jieba scikit-learn gradio google-generativeai -q\n",
        "\n",
        "# @title 2. åŒ¯å…¥å¥—ä»¶èˆ‡è¨­å®š\n",
        "# @markdown ---\n",
        "# @markdown åŒ¯å…¥æ‰€æœ‰æœƒç”¨åˆ°çš„ Python å‡½å¼åº«ã€‚\n",
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import pandas as pd\n",
        "import gspread\n",
        "from google.colab import auth\n",
        "from google.auth import default\n",
        "import jieba\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "import re\n",
        "import google.generativeai as genai\n",
        "import gradio as gr\n",
        "import time\n",
        "\n",
        "# @title 3. Google æœå‹™æˆæ¬Š\n",
        "# @markdown ---\n",
        "# @markdown åŸ·è¡Œæ­¤å„²å­˜æ ¼ä»¥æˆæ¬Š Colab å­˜å–æ‚¨çš„ Google å¸³æˆ¶ï¼Œä»¥ä¾¿æ“ä½œ Google Sheetã€‚\n",
        "try:\n",
        "    auth.authenticate_user()\n",
        "    creds, _ = default()\n",
        "    gc = gspread.authorize(creds)\n",
        "    print(\"âœ… Google æœå‹™æˆæ¬ŠæˆåŠŸï¼\")\n",
        "except Exception as e:\n",
        "    print(f\"ğŸ”´ æˆæ¬Šå¤±æ•—ï¼Œè«‹æª¢æŸ¥ API è¨­å®šæˆ–é‡æ–°åŸ·è¡Œã€‚éŒ¯èª¤è¨Šæ¯ï¼š{e}\")\n",
        "\n",
        "\n",
        "# @title 4. å®šç¾©æ ¸å¿ƒåŠŸèƒ½å‡½å¼\n",
        "# @markdown ---\n",
        "# @markdown é€™è£¡æˆ‘å€‘å°‡çˆ¬èŸ²ã€Google Sheet æ“ä½œã€æ–‡æœ¬åˆ†æå’Œ Gemini API ä¸²æ¥ç­‰åŠŸèƒ½éƒ½å°è£æˆç¨ç«‹çš„å‡½å¼ã€‚\n",
        "\n",
        "# 4.1 çˆ¬èŸ²å‡½å¼\n",
        "def scrape_ptt_movie(pages_to_fetch: int):\n",
        "    \"\"\"\n",
        "    çˆ¬å– PTT é›»å½±ç‰ˆæŒ‡å®šé æ•¸çš„æ–‡ç« åˆ—è¡¨ã€‚\n",
        "    \"\"\"\n",
        "    print(f\"ğŸš€ é–‹å§‹çˆ¬å– PTT é›»å½±ç‰ˆï¼Œå…± {pages_to_fetch} é ...\")\n",
        "    articles_data = []\n",
        "    headers = {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36', 'Cookie': 'over18=1'}\n",
        "\n",
        "    try:\n",
        "        response_index = requests.get(\"https://www.ptt.cc/bbs/movie/index.html\", headers=headers, timeout=10)\n",
        "        soup_index = BeautifulSoup(response_index.text, 'html.parser')\n",
        "        prev_button = soup_index.find('div', class_='btn-group-paging').find_all('a')[1]\n",
        "        latest_index = int(re.search(r'index(\\d+)\\.html', prev_button['href']).group(1)) + 1\n",
        "\n",
        "        for i in range(pages_to_fetch):\n",
        "            current_index = latest_index - i\n",
        "            url = f\"https://www.ptt.cc/bbs/movie/index{current_index}.html\"\n",
        "            print(f\"æ­£åœ¨çˆ¬å–ç¬¬ {i+1}/{pages_to_fetch} é : {url}\")\n",
        "            response = requests.get(url, headers=headers, timeout=10)\n",
        "            if response.status_code != 200:\n",
        "                print(f\"âš ï¸ é é¢ {url} è®€å–å¤±æ•—ï¼Œç‹€æ…‹ç¢¼: {response.status_code}\")\n",
        "                continue\n",
        "            soup = BeautifulSoup(response.text, 'html.parser')\n",
        "            for article in soup.find_all('div', class_='r-ent'):\n",
        "                title_tag = article.find('div', class_='title').find('a')\n",
        "                if title_tag:\n",
        "                    articles_data.append({\n",
        "                        'title': title_tag.text.strip(),\n",
        "                        'date': article.find('div', class_='date').text.strip(),\n",
        "                        'author': article.find('div', class_='author').text.strip(),\n",
        "                        'href': \"https://www.ptt.cc\" + title_tag['href']\n",
        "                    })\n",
        "            time.sleep(0.5)\n",
        "\n",
        "        df = pd.DataFrame(articles_data)\n",
        "        print(f\"âœ… çˆ¬å–å®Œæˆï¼Œå…±æŠ“å– {len(df)} ç¯‡æ–‡ç« ã€‚\")\n",
        "        return df\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"ğŸ”´ çˆ¬èŸ²éç¨‹ä¸­ç™¼ç”ŸéŒ¯èª¤: {e}\")\n",
        "        return pd.DataFrame()\n",
        "\n",
        "# 4.2 Google Sheet æ“ä½œå‡½å¼\n",
        "def write_to_sheet(df: pd.DataFrame, sheet_name: str, worksheet_name: str):\n",
        "    if df.empty:\n",
        "        print(f\"âš ï¸ DataFrame æ˜¯ç©ºçš„ï¼Œä¸å° '{worksheet_name}' åŸ·è¡Œå¯«å…¥æ“ä½œã€‚\")\n",
        "        return\n",
        "    print(f\"ğŸ“ æ­£åœ¨å°‡è³‡æ–™å¯«å…¥ Google Sheet '{sheet_name}' çš„ '{worksheet_name}' å·¥ä½œè¡¨...\")\n",
        "    try:\n",
        "        sh = gc.open(sheet_name)\n",
        "        try:\n",
        "            worksheet = sh.worksheet(worksheet_name)\n",
        "            worksheet.clear()\n",
        "        except gspread.WorksheetNotFound:\n",
        "            worksheet = sh.add_worksheet(title=worksheet_name, rows=\"1\", cols=\"1\")\n",
        "        worksheet.update([df.columns.values.tolist()] + df.values.tolist())\n",
        "        print(\"âœ… è³‡æ–™å¯«å…¥æˆåŠŸï¼\")\n",
        "    except Exception as e:\n",
        "        print(f\"ğŸ”´ å¯«å…¥ Google Sheet ('{worksheet_name}') æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}\")\n",
        "\n",
        "def read_from_sheet(sheet_name: str, worksheet_name: str):\n",
        "    print(f\"ğŸ“¥ æ­£åœ¨å¾ Google Sheet '{sheet_name}' çš„ '{worksheet_name}' å·¥ä½œè¡¨è®€å–è³‡æ–™...\")\n",
        "    try:\n",
        "        sh = gc.open(sheet_name)\n",
        "        worksheet = sh.worksheet(worksheet_name)\n",
        "        data = worksheet.get_all_records()\n",
        "        df = pd.DataFrame(data)\n",
        "        print(f\"âœ… è³‡æ–™è®€å–æˆåŠŸï¼å…± {len(df)} ç­†ã€‚\")\n",
        "        return df\n",
        "    except Exception as e:\n",
        "        print(f\"ğŸ”´ è®€å– Google Sheet æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}\")\n",
        "        return pd.DataFrame()\n",
        "\n",
        "# 4.3 æ–‡æœ¬åˆ†æå‡½å¼\n",
        "def analyze_text_tfidf(df: pd.DataFrame, top_n: int):\n",
        "    print(f\"ğŸ“Š æ­£åœ¨é€²è¡Œ TF-IDF åˆ†æï¼Œæ‰¾å‡ºå‰ {top_n} å€‹é—œéµå­—...\")\n",
        "    if df.empty or 'title' not in df.columns: return pd.DataFrame()\n",
        "    stopwords = {'çš„', 'äº†', 'æ˜¯', 'åœ¨', 'æˆ‘', 'ä½ ', 'ä»–', 'å¥¹', 'ä¹‹', 'ä¸€å€‹', 'å’Œ', 'è¨è«–', 'åˆ†äº«', 'å•é¡Œ', 'Re', 'Fw'}\n",
        "    corpus = df['title'].apply(lambda title: \" \".join([word for word in jieba.lcut(re.sub(r'[^\\u4e00-\\u9fa5a-zA-Z0-9\\s]', '', title)) if word.strip() and len(word) > 1 and word not in stopwords])).tolist()\n",
        "    try:\n",
        "        vectorizer = TfidfVectorizer()\n",
        "        tfidf_matrix = vectorizer.fit_transform(corpus)\n",
        "        feature_names = vectorizer.get_feature_names_out()\n",
        "        avg_tfidf_scores = tfidf_matrix.mean(axis=0).tolist()[0]\n",
        "        sorted_keywords = sorted(zip(feature_names, avg_tfidf_scores), key=lambda x: x[1], reverse=True)\n",
        "        top_keywords_df = pd.DataFrame(sorted_keywords[:top_n], columns=['keyword', 'tfidf_score']).round({'tfidf_score': 4})\n",
        "        print(\"âœ… TF-IDF åˆ†æå®Œæˆï¼\")\n",
        "        return top_keywords_df\n",
        "    except ValueError as e:\n",
        "        print(f\"ğŸ”´ TF-IDF åˆ†æå¤±æ•—: {e}ã€‚å¯èƒ½æ˜¯æ‰€æœ‰æ¨™é¡Œéƒ½è¢«éæ¿¾æ‰äº†ã€‚\")\n",
        "        return pd.DataFrame()\n",
        "\n",
        "def analyze_user_keywords(df: pd.DataFrame, user_keywords_str: str):\n",
        "    print(f\"ğŸ” æ­£åœ¨çµ±è¨ˆè‡ªè¨‚é—œéµå­—...\")\n",
        "    if df.empty or 'title' not in df.columns or not user_keywords_str:\n",
        "        print(\"âš ï¸ ç„¡æ³•é€²è¡Œè‡ªè¨‚é—œéµå­—çµ±è¨ˆ (è³‡æ–™ç‚ºç©ºæˆ–æœªè¼¸å…¥é—œéµå­—)ã€‚\")\n",
        "        return pd.DataFrame()\n",
        "\n",
        "    keywords = [kw.strip() for kw in re.split(r'[,ï¼Œ\\s]+', user_keywords_str) if kw.strip()]\n",
        "    if not keywords: return pd.DataFrame()\n",
        "\n",
        "    keyword_counts = {kw: 0 for kw in keywords}\n",
        "    for title in df['title']:\n",
        "        for kw in keywords:\n",
        "            if kw.lower() in title.lower():\n",
        "                keyword_counts[kw] += 1\n",
        "\n",
        "    counts_df = pd.DataFrame(list(keyword_counts.items()), columns=['user_keyword', 'count']).sort_values(by='count', ascending=False)\n",
        "    print(\"âœ… è‡ªè¨‚é—œéµå­—çµ±è¨ˆå®Œæˆï¼\")\n",
        "    return counts_df\n",
        "\n",
        "# 4.4 Gemini API ç›¸é—œå‡½å¼\n",
        "def test_gemini_api(api_key: str):\n",
        "    if not api_key:\n",
        "        return \"ğŸ”´ è«‹è¼¸å…¥æ‚¨çš„ Gemini API é‡‘é‘°ã€‚\"\n",
        "    try:\n",
        "        genai.configure(api_key=api_key)\n",
        "        # --- âœ¨ æœ€çµ‚æˆåŠŸç‰ˆä¿®æ”¹ âœ¨ ---\n",
        "        # ä½¿ç”¨ç¶“è¨ºæ–·å·¥å…·ç¢ºèªå¯ç”¨çš„ 'gemini-pro-latest' æ¨¡å‹\n",
        "        model = genai.GenerativeModel('gemini-pro-latest')\n",
        "        response = model.generate_content(\"ä½ å¥½\", generation_config=genai.types.GenerationConfig(\n",
        "        candidate_count=1, max_output_tokens=5))\n",
        "        return \"âœ… API é‡‘é‘°é©—è­‰æˆåŠŸï¼å¯ä»¥æ­£å¸¸é€£ç·šã€‚\"\n",
        "    except Exception as e:\n",
        "        return f\"ğŸ”´ API é‡‘é‘°é©—è­‰å¤±æ•—ï¼\\n\\néŒ¯èª¤è¨Šæ¯ï¼š{str(e)[:500]}...\\n\\nè«‹åƒè€ƒä»‹é¢ä¸Šçš„ã€Œç–‘é›£æ’è§£ã€èªªæ˜é€²è¡Œæª¢æŸ¥ã€‚\"\n",
        "\n",
        "def generate_summary_with_gemini(api_key: str, keywords_df: pd.DataFrame):\n",
        "    print(\"ğŸ¤– æ­£åœ¨ä½¿ç”¨ Gemini API ç”Ÿæˆæ‘˜è¦...\")\n",
        "    if keywords_df.empty: return \"ç„¡æ³•ç”Ÿæˆæ‘˜è¦ï¼Œå› ç‚ºæ²’æœ‰æä¾›é—œéµå­—ã€‚\", \"ç„¡æ³•ç”Ÿæˆçµè«–ã€‚\"\n",
        "    try:\n",
        "        genai.configure(api_key=api_key)\n",
        "        # --- âœ¨ æœ€çµ‚æˆåŠŸç‰ˆä¿®æ”¹ âœ¨ ---\n",
        "        # ä½¿ç”¨ç¶“è¨ºæ–·å·¥å…·ç¢ºèªå¯ç”¨çš„ 'gemini-pro-latest' æ¨¡å‹\n",
        "        model = genai.GenerativeModel('gemini-pro-latest')\n",
        "        keywords_list = keywords_df['keyword'].tolist()\n",
        "        prompt = f\"ä½ æ˜¯ä¸€ä½å°ˆæ¥­çš„ç¤¾ç¾¤è¼¿æƒ…åˆ†æå¸«ã€‚è«‹æ ¹æ“šä»¥ä¸‹å¾ PTT é›»å½±ç‰ˆæ–‡ç« æ¨™é¡Œä¸­æå–å‡ºçš„ç†±é–€é—œéµå­—ï¼š[{', '.join(keywords_list)}]ï¼ŒåŸ·è¡Œä»¥ä¸‹å…©é …ä»»å‹™ï¼š\\n\\nä»»å‹™ä¸€ï¼šç”¢ç”Ÿäº”å¥æ¢åˆ—å¼çš„å¸‚å ´æ´å¯Ÿèˆ‡è¶¨å‹¢åˆ†æã€‚\\nä»»å‹™äºŒï¼šæ ¹æ“šä»¥ä¸Šçš„æ´å¯Ÿï¼Œæ’°å¯«ä¸€æ®µç´„ 120 å­—çš„ç¸½çµã€‚\\n\\nè«‹ç”¨ç¹é«”ä¸­æ–‡å›ç­”ï¼Œä¸¦ç›´æ¥æä¾›çµæœã€‚\"\n",
        "        response = model.generate_content(prompt)\n",
        "        clean_text = response.text.replace('**', '').replace('*', '').strip()\n",
        "        parts = re.split(r'ç¸½çµï¼š|çµè«–ï¼š', clean_text)\n",
        "        summary, conclusion = (parts[0].strip(), parts[1].strip()) if len(parts) > 1 else (clean_text, \"çµè«–ç„¡æ³•å¾å›æ‡‰ä¸­åˆ†é›¢ã€‚\")\n",
        "        print(\"âœ… Gemini æ‘˜è¦ç”ŸæˆæˆåŠŸï¼\")\n",
        "        return summary, conclusion\n",
        "    except Exception as e:\n",
        "        print(f\"ğŸ”´ Gemini API å‘¼å«å¤±æ•—: {e}\")\n",
        "        return f\"API å‘¼å«å¤±æ•—: {e}\", \"ç„¡æ³•ç”Ÿæˆçµè«–ã€‚\"\n",
        "\n",
        "# @title 5. æ•´åˆä¸»è¦å·¥ä½œæµç¨‹\n",
        "# @markdown ---\n",
        "# @markdown é€™å€‹å‡½å¼æœƒå°‡ä¸Šè¿°æ‰€æœ‰åŠŸèƒ½ä¸²é€£èµ·ä¾†ï¼Œå½¢æˆä¸€å€‹å®Œæ•´çš„è‡ªå‹•åŒ–æµç¨‹ã€‚\n",
        "def run_analysis_pipeline(pages: int, sheet_name: str, top_n: int, user_keywords_str: str, gemini_api_key: str):\n",
        "    if not sheet_name or not gemini_api_key:\n",
        "        return pd.DataFrame(), pd.DataFrame(), pd.DataFrame(), \"\", \"\", \"ğŸ”´ éŒ¯èª¤ï¼šè«‹å‹™å¿…å¡«å¯« Google Sheet æª”æ¡ˆåç¨±èˆ‡ Gemini API é‡‘é‘°ã€‚\"\n",
        "\n",
        "    scraped_df = scrape_ptt_movie(pages)\n",
        "    if scraped_df.empty: return pd.DataFrame(), pd.DataFrame(), pd.DataFrame(), \"\", \"\", \"ğŸ”´ çˆ¬èŸ²å¤±æ•—ï¼Œæµç¨‹ä¸­æ­¢ã€‚\"\n",
        "    write_to_sheet(scraped_df, sheet_name, \"çˆ¬èŸ²åŸå§‹è³‡æ–™\")\n",
        "\n",
        "    read_df = read_from_sheet(sheet_name, \"çˆ¬èŸ²åŸå§‹è³‡æ–™\")\n",
        "    if read_df.empty: return scraped_df, pd.DataFrame(), pd.DataFrame(), \"\", \"\", \"ğŸ”´ å¾ Google Sheet è®€å–è³‡æ–™å¤±æ•—ï¼Œæµç¨‹ä¸­æ­¢ã€‚\"\n",
        "\n",
        "    tfidf_keywords_df = analyze_text_tfidf(read_df, top_n)\n",
        "    write_to_sheet(tfidf_keywords_df, sheet_name, \"TF-IDFé—œéµå­—çµ±è¨ˆ\")\n",
        "\n",
        "    user_keywords_df = analyze_user_keywords(read_df, user_keywords_str)\n",
        "    write_to_sheet(user_keywords_df, sheet_name, \"è‡ªè¨‚é—œéµå­—è¿½è¹¤\")\n",
        "\n",
        "    summary, conclusion = generate_summary_with_gemini(gemini_api_key, tfidf_keywords_df)\n",
        "\n",
        "    status_message = \"âœ… æ‰€æœ‰æµç¨‹åŸ·è¡ŒæˆåŠŸï¼\"\n",
        "    print(f\"\\n{'='*50}\\n{status_message}\\n{'='*50}\\n\")\n",
        "    return scraped_df, tfidf_keywords_df, user_keywords_df, summary, conclusion, status_message\n",
        "\n",
        "\n",
        "# @title 6. å»ºç«‹ Gradio ä½¿ç”¨è€…ä»‹é¢\n",
        "# @markdown ---\n",
        "# @markdown åŸ·è¡Œæ­¤å„²å­˜æ ¼ä¾†å•Ÿå‹• Gradio äº’å‹•ä»‹é¢ã€‚\n",
        "def create_gradio_interface():\n",
        "    print(\"ğŸš€ æ­£åœ¨å•Ÿå‹• Gradio ä»‹é¢...\")\n",
        "    with gr.Blocks(theme=gr.themes.Soft(), title=\"PTT é›»å½±ç‰ˆè¼¿æƒ…åˆ†æ\") as demo:\n",
        "        gr.Markdown(\"# ğŸ“ˆ PTT é›»å½±ç‰ˆè¼¿æƒ…åˆ†ææ©Ÿå™¨äºº (v6)\")\n",
        "\n",
        "        with gr.Accordion(\"äº‹å‰æº–å‚™ & Gemini API ç–‘é›£æ’è§£\", open=False):\n",
        "            gr.Markdown(\n",
        "                \"\"\"\n",
        "                ### **äº‹å‰æº–å‚™**\n",
        "                1.  **å»ºç«‹å…¨æ–° Google Cloud å°ˆæ¡ˆ**ï¼šç‚ºç¢ºä¿è¨­å®šä¹¾æ·¨ï¼Œå»ºè­°å»ºç«‹ä¸€å€‹å…¨æ–°çš„å°ˆæ¡ˆä¾†ç”¢ç”Ÿ API é‡‘é‘°ã€‚\n",
        "                2.  **å•Ÿç”¨ API**ï¼šåœ¨æ–°å°ˆæ¡ˆä¸­ï¼Œå‹™å¿…å•Ÿç”¨ \"Generative Language API\"ã€‚\n",
        "                3.  **å»ºç«‹å…¨æ–° API é‡‘é‘°**ï¼šåœ¨æ–°å°ˆæ¡ˆä¸­ï¼Œå»ºç«‹ä¸€çµ„å…¨æ–°çš„ API é‡‘é‘°ã€‚\n",
        "                4.  **åˆ†äº«æ¬Šé™**ï¼šå°‡æ­¤ Colab çš„æœå‹™å¸³è™Ÿ Email (åœ¨ç¬¬ 3 æ­¥ã€ŒGoogle æœå‹™æˆæ¬Šã€çš„è¼¸å‡ºä¸­å°‹æ‰¾) åŠ å…¥ç‚ºè©² Google Sheet çš„ã€Œ**ç·¨è¼¯è€…**ã€ã€‚\n",
        "                \"\"\"\n",
        "            )\n",
        "\n",
        "        gr.Markdown(\"### ğŸ› ï¸ æ­¥é©Ÿä¸€ï¼šæ¸¬è©¦ Gemini API é‡‘é‘° (å¯é¸ï¼Œä½†å»ºè­°åˆæ¬¡ä½¿ç”¨æ™‚æ¸¬è©¦)\")\n",
        "        with gr.Row():\n",
        "            gemini_api_key_test_input = gr.Textbox(label=\"åœ¨æ­¤è²¼ä¸Šæ‚¨çš„ Gemini API é‡‘é‘°é€²è¡Œæ¸¬è©¦\", type=\"password\")\n",
        "            test_api_button = gr.Button(\"ğŸ§ª æ¸¬è©¦ API é‡‘é‘°\")\n",
        "        test_api_output = gr.Textbox(label=\"æ¸¬è©¦çµæœ\", interactive=False)\n",
        "        test_api_button.click(fn=test_gemini_api, inputs=[gemini_api_key_test_input], outputs=[test_api_output])\n",
        "\n",
        "        gr.Markdown(\"---\")\n",
        "        gr.Markdown(\"### âš™ï¸ æ­¥é©ŸäºŒï¼šè¼¸å…¥åƒæ•¸ä¸¦åŸ·è¡Œå®Œæ•´æµç¨‹\")\n",
        "        with gr.Row():\n",
        "            with gr.Column(scale=1):\n",
        "                pages_input = gr.Slider(minimum=1, maximum=20, value=5, step=1, label=\"è¦çˆ¬å–çš„é æ•¸\")\n",
        "                sheet_name_input = gr.Textbox(label=\"Google Sheet æª”æ¡ˆåç¨±\", info=\"è«‹ç¢ºä¿åç¨±èˆ‡æ‚¨çš„æª”æ¡ˆå®Œå…¨ä¸€è‡´ã€‚\")\n",
        "                top_n_input = gr.Slider(minimum=5, maximum=20, value=10, step=1, label=\"TF-IDF ç†±é–€é—œéµå­—æ•¸é‡ (Top N)\")\n",
        "                user_keywords_input = gr.Textbox(label=\"è«‹è¼¸å…¥æ‚¨æƒ³è¿½è¹¤çš„é—œéµå­—\", info=\"ä»¥é€—è™Ÿæˆ–ç©ºæ ¼åˆ†éš”ï¼Œä¾‹å¦‚ï¼šæ²™ä¸˜, å“¥å‰æ‹‰, å¥§æœ¬æµ·é»˜\")\n",
        "                gemini_api_key_input = gr.Textbox(label=\"Gemini API é‡‘é‘°\", type=\"password\", info=\"åŸ·è¡Œå®Œæ•´æµç¨‹éœ€è¦å†æ¬¡è¼¸å…¥é‡‘é‘°ã€‚\")\n",
        "                run_button = gr.Button(\"ğŸš€ é–‹å§‹åŸ·è¡Œåˆ†æ\", variant=\"primary\")\n",
        "\n",
        "            with gr.Column(scale=2):\n",
        "                status_output = gr.Textbox(label=\"åŸ·è¡Œç‹€æ…‹\", interactive=False)\n",
        "                with gr.Tab(\"AI æ´å¯Ÿèˆ‡çµè«–\"):\n",
        "                    summary_output = gr.Markdown(label=\"Gemini æ´å¯Ÿæ‘˜è¦\")\n",
        "                    conclusion_output = gr.Textbox(label=\"Gemini çµè«–\", lines=4, interactive=False)\n",
        "                with gr.Tab(\"TF-IDF é—œéµå­—çµ±è¨ˆ\"):\n",
        "                    tfidf_output = gr.DataFrame(headers=[\"keyword\", \"tfidf_score\"], label=\"è‡ªå‹•åˆ†æç†±è©\")\n",
        "                with gr.Tab(\"è‡ªè¨‚é—œéµå­—è¿½è¹¤\"):\n",
        "                    user_keywords_output = gr.DataFrame(headers=[\"user_keyword\", \"count\"], label=\"æ‰‹å‹•è¿½è¹¤è©é »\")\n",
        "                with gr.Tab(\"çˆ¬èŸ²åŸå§‹è³‡æ–™\"):\n",
        "                    scraped_data_output = gr.DataFrame(label=\"æŠ“å–çš„æ–‡ç« åˆ—è¡¨\")\n",
        "\n",
        "        run_button.click(\n",
        "            fn=run_analysis_pipeline,\n",
        "            inputs=[pages_input, sheet_name_input, top_n_input, user_keywords_input, gemini_api_key_input],\n",
        "            outputs=[scraped_data_output, tfidf_output, user_keywords_output, summary_output, conclusion_output, status_output]\n",
        "        )\n",
        "\n",
        "    demo.launch(debug=True, share=True)\n",
        "\n",
        "# åŸ·è¡Œå‡½å¼ä»¥å•Ÿå‹•ä»‹é¢\n",
        "create_gradio_interface()"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/jieba/__init__.py:44: SyntaxWarning: invalid escape sequence '\\.'\n",
            "  re_han_default = re.compile(\"([\\u4E00-\\u9FD5a-zA-Z0-9+#&\\._%\\-]+)\", re.U)\n",
            "/usr/local/lib/python3.12/dist-packages/jieba/__init__.py:46: SyntaxWarning: invalid escape sequence '\\s'\n",
            "  re_skip_default = re.compile(\"(\\r\\n|\\s)\", re.U)\n",
            "/usr/local/lib/python3.12/dist-packages/jieba/finalseg/__init__.py:78: SyntaxWarning: invalid escape sequence '\\.'\n",
            "  re_skip = re.compile(\"([a-zA-Z0-9]+(?:\\.\\d+)?%?)\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… Google æœå‹™æˆæ¬ŠæˆåŠŸï¼\n",
            "ğŸš€ æ­£åœ¨å•Ÿå‹• Gradio ä»‹é¢...\n",
            "Colab notebook detected. This cell will run indefinitely so that you can see errors and logs. To turn off, set debug=False in launch().\n",
            "* Running on public URL: https://55a78d2bd28484d59c.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://55a78d2bd28484d59c.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ğŸš€ é–‹å§‹çˆ¬å– PTT é›»å½±ç‰ˆï¼Œå…± 5 é ...\n",
            "æ­£åœ¨çˆ¬å–ç¬¬ 1/5 é : https://www.ptt.cc/bbs/movie/index10812.html\n",
            "æ­£åœ¨çˆ¬å–ç¬¬ 2/5 é : https://www.ptt.cc/bbs/movie/index10811.html\n",
            "æ­£åœ¨çˆ¬å–ç¬¬ 3/5 é : https://www.ptt.cc/bbs/movie/index10810.html\n",
            "æ­£åœ¨çˆ¬å–ç¬¬ 4/5 é : https://www.ptt.cc/bbs/movie/index10809.html\n",
            "æ­£åœ¨çˆ¬å–ç¬¬ 5/5 é : https://www.ptt.cc/bbs/movie/index10808.html\n",
            "âœ… çˆ¬å–å®Œæˆï¼Œå…±æŠ“å– 96 ç¯‡æ–‡ç« ã€‚\n",
            "ğŸ“ æ­£åœ¨å°‡è³‡æ–™å¯«å…¥ Google Sheet 'HW4' çš„ 'çˆ¬èŸ²åŸå§‹è³‡æ–™' å·¥ä½œè¡¨...\n",
            "âœ… è³‡æ–™å¯«å…¥æˆåŠŸï¼\n",
            "ğŸ“¥ æ­£åœ¨å¾ Google Sheet 'HW4' çš„ 'çˆ¬èŸ²åŸå§‹è³‡æ–™' å·¥ä½œè¡¨è®€å–è³‡æ–™...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Building prefix dict from the default dictionary ...\n",
            "DEBUG:jieba:Building prefix dict from the default dictionary ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… è³‡æ–™è®€å–æˆåŠŸï¼å…± 96 ç­†ã€‚\n",
            "ğŸ“Š æ­£åœ¨é€²è¡Œ TF-IDF åˆ†æï¼Œæ‰¾å‡ºå‰ 10 å€‹é—œéµå­—...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Dumping model to file cache /tmp/jieba.cache\n",
            "DEBUG:jieba:Dumping model to file cache /tmp/jieba.cache\n",
            "Loading model cost 0.810 seconds.\n",
            "DEBUG:jieba:Loading model cost 0.810 seconds.\n",
            "Prefix dict has been built successfully.\n",
            "DEBUG:jieba:Prefix dict has been built successfully.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… TF-IDF åˆ†æå®Œæˆï¼\n",
            "ğŸ“ æ­£åœ¨å°‡è³‡æ–™å¯«å…¥ Google Sheet 'HW4' çš„ 'TF-IDFé—œéµå­—çµ±è¨ˆ' å·¥ä½œè¡¨...\n",
            "âœ… è³‡æ–™å¯«å…¥æˆåŠŸï¼\n",
            "ğŸ” æ­£åœ¨çµ±è¨ˆè‡ªè¨‚é—œéµå­—...\n",
            "âœ… è‡ªè¨‚é—œéµå­—çµ±è¨ˆå®Œæˆï¼\n",
            "ğŸ“ æ­£åœ¨å°‡è³‡æ–™å¯«å…¥ Google Sheet 'HW4' çš„ 'è‡ªè¨‚é—œéµå­—è¿½è¹¤' å·¥ä½œè¡¨...\n",
            "âœ… è³‡æ–™å¯«å…¥æˆåŠŸï¼\n",
            "ğŸ¤– æ­£åœ¨ä½¿ç”¨ Gemini API ç”Ÿæˆæ‘˜è¦...\n",
            "âœ… Gemini æ‘˜è¦ç”ŸæˆæˆåŠŸï¼\n",
            "\n",
            "==================================================\n",
            "âœ… æ‰€æœ‰æµç¨‹åŸ·è¡ŒæˆåŠŸï¼\n",
            "==================================================\n",
            "\n",
            "Keyboard interruption in main thread... closing server.\n",
            "Killing tunnel 127.0.0.1:7860 <> https://55a78d2bd28484d59c.gradio.live\n"
          ]
        }
      ],
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "-EQj-LPCET0d",
        "outputId": "7c016cd8-4d39-4343-a683-94a577fb2068"
      }
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}